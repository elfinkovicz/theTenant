# Terraform Best Practices f√ºr dieses Projekt

## Problem: Unn√∂tige Ressourcen-Neuerststellungen

Bei jedem `terraform apply` werden viele Ressourcen unn√∂tig neu erstellt oder aktualisiert. Dies f√ºhrt zu:
- L√§ngeren Deployment-Zeiten
- Potenziellen Ausfallzeiten
- Datenverlust bei S3 Buckets
- Unn√∂tigen Kosten

## L√∂sungen

### 1. S3 Buckets sch√ºtzen

**Problem:** S3 Buckets werden neu erstellt, was alle Inhalte l√∂scht.

**L√∂sung:** `lifecycle`-Bl√∂cke mit `prevent_destroy` und `ignore_changes` hinzuf√ºgen:

```hcl
resource "aws_s3_bucket" "website" {
  bucket = "${var.project_name}-website-${data.aws_caller_identity.current.account_id}"
  
  lifecycle {
    prevent_destroy = true
    ignore_changes = [tags, tags_all, bucket]
  }
}
```

**Bereits gesch√ºtzt:**
- ‚úÖ `modules/s3-website/main.tf` - Website Bucket
- ‚úÖ `modules/shop/main.tf` - Product Images Bucket  
- ‚úÖ `modules/sponsor-system/main.tf` - Sponsor Assets Bucket

### 2. Lambda-Funktionen: Source Code Hash

**Problem:** Lambda-Funktionen werden bei jedem Apply aktualisiert, auch wenn sich der Code nicht ge√§ndert hat.

**Ursache:** 
- `archive_file` data source erstellt bei jedem Run einen neuen Hash
- Timestamps in ZIP-Dateien √§ndern sich
- Whitespace-√Ñnderungen in inline Code

**L√∂sung 1:** `ignore_changes` f√ºr `source_code_hash`:

```hcl
resource "aws_lambda_function" "example" {
  # ... andere Konfiguration ...
  
  lifecycle {
    ignore_changes = [source_code_hash, last_modified]
  }
}
```

**L√∂sung 2:** Externe ZIP-Dateien mit festem Hash verwenden (besser f√ºr Production):

```hcl
resource "aws_lambda_function" "example" {
  filename         = "${path.module}/lambda/function.zip"
  source_code_hash = filebase64sha256("${path.module}/lambda/function.zip")
  
  # Nur aktualisieren wenn ZIP sich √§ndert
}
```

### 3. DynamoDB Tables

**Problem:** Tables werden neu erstellt bei Konfigurations√§nderungen.

**L√∂sung:** `prevent_destroy` hinzuf√ºgen:

```hcl
resource "aws_dynamodb_table" "example" {
  # ... Konfiguration ...
  
  lifecycle {
    prevent_destroy = true
    ignore_changes = [tags, tags_all]
  }
}
```

### 4. Cognito User Pools

**Problem:** User Pool wird neu erstellt, alle Benutzer gehen verloren.

**L√∂sung:** `prevent_destroy` und `ignore_changes`:

```hcl
resource "aws_cognito_user_pool" "main" {
  # ... Konfiguration ...
  
  lifecycle {
    prevent_destroy = true
    ignore_changes = [
      tags,
      tags_all,
      schema,  # Schema kann nicht ge√§ndert werden
      email_configuration  # Oft nur Formatierung
    ]
  }
}
```

### 5. IVS Channels

**Problem:** IVS Channel wird neu erstellt, Stream Key √§ndert sich.

**L√∂sung:**

```hcl
resource "aws_ivs_channel" "main" {
  # ... Konfiguration ...
  
  lifecycle {
    prevent_destroy = true
    ignore_changes = [tags, tags_all]
  }
}
```

## Deployment-Workflow

### Vor jedem Apply:

1. **Plan erstellen und pr√ºfen:**
   ```bash
   cd TerraformInfluencerTemplate
   terraform plan -var-file="clients/honigwabe/terraform.tfvars" -out=tfplan
   ```

2. **Plan analysieren:**
   - Suche nach `must be replaced` (üö® KRITISCH!)
   - Suche nach `will be destroyed` (üö® KRITISCH!)
   - Pr√ºfe `will be created` (meist OK)
   - Pr√ºfe `will be updated in-place` (meist OK)

3. **Kritische Ressourcen identifizieren:**
   ```bash
   # Zeige nur kritische √Ñnderungen
   terraform plan -var-file="clients/honigwabe/terraform.tfvars" 2>&1 | findstr /C:"must be replaced" /C:"will be destroyed"
   ```

4. **Bei kritischen √Ñnderungen:**
   - ‚ùå NICHT apply ausf√ºhren!
   - Pr√ºfe warum die Ressource neu erstellt wird
   - F√ºge `lifecycle`-Bl√∂cke hinzu
   - Erstelle neuen Plan

### Safe Apply:

```bash
# Nur wenn Plan sicher ist:
terraform apply tfplan
```

## H√§ufige Ursachen f√ºr Neuerststellungen

### 1. Bucket Name √§ndert sich
```hcl
# FALSCH:
bucket = "${var.project_name}-${random_id.bucket.hex}"

# RICHTIG:
bucket = "${var.project_name}-website-${data.aws_caller_identity.current.account_id}"

# Mit Schutz:
lifecycle {
  ignore_changes = [bucket]
}
```

### 2. Inline Lambda Code
```hcl
# PROBLEM: Bei jedem Apply neuer Hash
data "archive_file" "lambda" {
  type = "zip"
  source {
    content  = <<-EOT
      // Code hier
    EOT
    filename = "index.js"
  }
}

# L√ñSUNG: Externe Datei oder ignore_changes
```

### 3. Tags √§ndern sich
```hcl
# Immer hinzuf√ºgen:
lifecycle {
  ignore_changes = [tags, tags_all]
}
```

### 4. Computed Values
```hcl
# PROBLEM: Wert √§ndert sich bei jedem Run
domain_name = aws_s3_bucket.website.bucket_regional_domain_name

# L√ñSUNG: ignore_changes oder fester Wert
```

## Notfall: Ressource aus State entfernen

Wenn eine Ressource f√§lschlicherweise neu erstellt werden soll:

```bash
# 1. Aus State entfernen (Ressource bleibt in AWS!)
terraform state rm module.website.aws_s3_bucket.website

# 2. Neu importieren
terraform import module.website.aws_s3_bucket.website honigwabe-website-081033004511

# 3. Plan pr√ºfen
terraform plan -var-file="clients/honigwabe/terraform.tfvars"
```

## Checkliste vor Production Deploy

- [ ] `terraform plan` zeigt keine `must be replaced`
- [ ] Alle S3 Buckets haben `prevent_destroy = true`
- [ ] Alle DynamoDB Tables haben `prevent_destroy = true`
- [ ] Cognito User Pool hat `prevent_destroy = true`
- [ ] IVS Channel hat `prevent_destroy = true`
- [ ] Lambda-Funktionen haben `ignore_changes = [source_code_hash]` oder externe ZIPs
- [ ] Backup der terraform.tfstate erstellt
- [ ] Backup der wichtigen S3 Buckets erstellt

## Monitoring nach Apply

```bash
# CloudWatch Logs pr√ºfen
aws logs tail /aws/lambda/honigwabe-video-api --follow

# S3 Bucket Inhalt pr√ºfen
aws s3 ls s3://honigwabe-website-081033004511/

# Lambda-Funktionen Status
aws lambda list-functions --query 'Functions[?starts_with(FunctionName, `honigwabe`)].FunctionName'
```

## Weitere Ressourcen

- [Terraform Lifecycle Meta-Argument](https://www.terraform.io/language/meta-arguments/lifecycle)
- [Terraform State Management](https://www.terraform.io/language/state)
- [AWS Provider Best Practices](https://registry.terraform.io/providers/hashicorp/aws/latest/docs)
